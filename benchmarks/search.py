from typing import Callable
import time
import multiprocessing as mp

import numpy as np
import torch
import polars as pl
import gymnasium as gym
from gymnasium.vector import SyncVectorEnv, AsyncVectorEnv

from envrunner import EnvExecutor
from cartpole import CartPoleEnv
from utils import FakeStochasticPolicy, FakeGPUPolicy


class EnvMaker:
    """
    ä¸€ä¸ªå¯åºåˆ—åŒ–çš„ç±»ï¼Œç”¨äºåˆ›å»ºç¯å¢ƒå®ä¾‹ã€‚
    """

    def __init__(self):
        pass

    def __call__(self) -> gym.Env:
        """
        è¿™ä¸ªæ–¹æ³•å°†åœ¨å­è¿›ç¨‹ä¸­è¢«è°ƒç”¨ï¼Œä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ç¯å¢ƒå®ä¾‹ã€‚
        """
        return CartPoleEnv()


# --- 2. æ ¸å¿ƒæµ‹é‡å‡½æ•° (æ›´æ–°å) ---
def run_trial_with_gpu(
    algorithm_cls: Callable,
    num_envs: int,
    num_workers: int,
    effective_batch_size: int,
    policy: FakeGPUPolicy,
    num_trials: int = 50,
) -> float:
    """è¿è¡Œä¸€æ¬¡åŒ…å« GPU æ¨ç†çš„æµ‹è¯•å¹¶è¿”å› FPSã€‚"""

    # æ­¥éª¤ 2 - é…ç½®æ‚¨çš„ç¯å¢ƒæ„é€ å‡½æ•°
    # ==============================================================================

    env_fns = [EnvMaker() for _ in range(num_envs)]
    # ==============================================================================

    env = None
    try:
        # åˆå§‹åŒ–ç¯å¢ƒæ‰§è¡Œå™¨
        if algorithm_cls is EnvExecutor:
            env = algorithm_cls(env_fns, num_workers=num_workers)
        else:
            env = algorithm_cls(env_fns)

        # ä½¿ç”¨ä¼ å…¥çš„ policy
        obs, _ = env.reset(seed=42)

        # é¢„çƒ­ (åŒ…æ‹¬JITç¼–è¯‘å’ŒGPUç¼“å­˜)
        for _ in range(5):
            actions = policy.get_actions(obs)
            obs, _, _, _, _ = env.step(actions)

        total_time = 0
        for _ in range(num_trials):
            start = time.perf_counter()
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çœŸå®çš„ obs
            actions = policy.get_actions(obs)
            obs, _, _, _, _ = env.step(actions)
            end = time.perf_counter()
            total_time += end - start

        avg_time_per_step = total_time / num_trials
        fps = effective_batch_size / avg_time_per_step
        return fps

    except Exception as e:
        print(f"  - WARN: Config failed with error: {e}")
        return 0.0
    finally:
        if env:
            env.close()


# --- æ ¸å¿ƒæµ‹é‡å‡½æ•° ---
def run_trial(
    algorithm_cls: Callable,
    num_envs: int,
    num_workers: int,
    effective_batch_size: int,
    num_trials: int = 20,  # å‡å°‘ trial æ¬¡æ•°ä»¥åŠ å¿«æœç´¢
) -> float:
    """è¿è¡Œä¸€æ¬¡æµ‹è¯•å¹¶è¿”å› FPSã€‚"""

    env_fns = [lambda: CartPoleEnv() for _ in range(num_envs)]
    # ==============================================================================

    env = None
    try:
        if algorithm_cls is EnvExecutor:
            env = algorithm_cls(env_fns, num_workers=num_workers)
            policy = FakeStochasticPolicy(
                env.action_space, is_vectorized_action_space=False
            )
        else:
            env = algorithm_cls(env_fns)
            policy = FakeStochasticPolicy(
                env.action_space, is_vectorized_action_space=True
            )

        dummy_obs = np.zeros(
            (num_envs,) + env.single_observation_space.shape,
            dtype=env.single_observation_space.dtype,
        )
        env.reset(seed=42)

        # é¢„çƒ­
        env.step(policy.get_actions(dummy_obs))

        total_time = 0
        for _ in range(num_trials):
            start = time.perf_counter()
            env.step(policy.get_actions(dummy_obs))
            end = time.perf_counter()
            total_time += end - start

        avg_time_per_step = total_time / num_trials
        fps = effective_batch_size / avg_time_per_step
        return fps

    except Exception as e:
        # æ•è·é”™è¯¯å¹¶è¿”å› 0 FPSï¼Œè¡¨ç¤ºæ­¤é…ç½®ä¸å¯è¡Œ
        # print(f"  - WARN: Config failed with error: {e}")
        return 0.0
    finally:
        if env:
            env.close()


# --- ä¸»æœç´¢ç¨‹åº ---
def main():
    # --- 1. å®šä¹‰æœç´¢ç©ºé—´ ---
    # æ‚¨çš„ GPU å†…å­˜å·¨å¤§ï¼Œå¯ä»¥æ‰¿å—éå¸¸å¤§çš„æ‰¹æ¬¡
    BATCH_SIZES = [256, 512, 1024, 2048, 4096, 8192, 16384]
    # i9-14900K: 8 P-cores, 16 E-cores. æµ‹è¯• P-core æ•°é‡ï¼Œæ€»æ ¸å¿ƒæ•°ï¼Œæ€»çº¿ç¨‹æ•°ç­‰
    WORKER_COUNTS = [4, 8, 12, 16, 24, 32]
    ALGORITHMS = {
        "EnvExecutor": EnvExecutor,
        "AsyncVectorEnv": AsyncVectorEnv,
        "SyncVectorEnv": SyncVectorEnv,
    }

    cpu_cores = mp.cpu_count()
    # --- GPU è®¾ç½® ---
    if not torch.cuda.is_available():
        print("é”™è¯¯: æœ¬è„šæœ¬éœ€è¦ CUDA-enabled GPUã€‚")
        return
    # ä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€å— RTX 5090
    device = torch.device("cuda:0")
    print("=" * 70)
    print("      å…¨ç³»ç»Ÿ (CPU+GPU) RL é‡‡æ ·é…ç½®æœç´¢ç¨‹åº")
    print(f"ç¡¬ä»¶: i9-14900K ({cpu_cores} æ ¸å¿ƒ), 2x RTX 5090 (ä½¿ç”¨ {device})")
    print(f"ç›®æ ‡: æœ€å¤§åŒ–ç«¯åˆ°ç«¯çš„åŒæ­¥ FPS")
    print("=" * 70)

    # --- åˆå§‹åŒ–å…±äº«çš„ GPU ç­–ç•¥ ---
    # ä¸€ä¸ªä¸´æ—¶ç¯å¢ƒæ¥æ¨æ–­ obs å’Œ action çš„ç»´åº¦
    temp_env = CartPoleEnv()
    obs_dim = temp_env.observation_space.shape[0]  # type: ignore
    act_dim = temp_env.action_space.n  # type: ignore
    temp_env.close()

    # åˆ›å»ºä¸€ä¸ªå°†åœ¨æ‰€æœ‰æµ‹è¯•ä¸­å…±äº«çš„ç­–ç•¥å®ä¾‹
    shared_policy = FakeGPUPolicy(
        obs_dim, act_dim, gym.spaces.Discrete(act_dim), device
    )

    # --- 2. åˆ›å»ºæ‰€æœ‰æµ‹è¯•é…ç½® ---
    all_configs = []
    for algo_name, algo_cls in ALGORITHMS.items():
        if algo_name == "EnvExecutor":
            for batch_size in BATCH_SIZES:
                for workers in WORKER_COUNTS:
                    if batch_size % workers == 0:  # ç¡®ä¿å¯ä»¥æ•´é™¤
                        all_configs.append((algo_name, algo_cls, batch_size, workers))
        elif algo_name == "AsyncVectorEnv":
            # å¯¹äº Async, å®ƒçš„åŒæ­¥æ‰¹å¤§å°å°±æ˜¯å…¶è¿›ç¨‹æ•°
            for workers in WORKER_COUNTS:
                all_configs.append(
                    (algo_name, algo_cls, workers, workers)
                )  # batch_size = workers
        elif algo_name == "SyncVectorEnv":
            # å¯¹äº Sync, å®ƒåªæœ‰ä¸€ä¸ªè¿›ç¨‹
            for batch_size in BATCH_SIZES:
                all_configs.append((algo_name, algo_cls, batch_size, 1))

    # --- 3. è¿è¡Œæœç´¢ ---
    results = []
    total_configs = len(all_configs)
    print(f"[*] å°†è¦æµ‹è¯• {total_configs} ç§ä¸åŒé…ç½®...\n")

    for i, (algo_name, algo_cls, batch_size, workers) in enumerate(all_configs):

        # å¯¹äº Async, effective_batch_size å°±æ˜¯ workers
        effective_batch_size = workers if algo_name == "AsyncVectorEnv" else batch_size
        num_envs_to_create = workers if algo_name == "AsyncVectorEnv" else batch_size

        print(
            f"[{i+1}/{total_configs}] æµ‹è¯•: {algo_name}, Batch={batch_size}, Workers={workers}... ",
            end="",
            flush=True,
        )

        # fps = run_trial(algo_cls, num_envs_to_create, workers, effective_batch_size)
        fps = run_trial_with_gpu(
            algo_cls, num_envs_to_create, workers, effective_batch_size, shared_policy
        )

        print(f"-> FPS: {fps:,.0f}")
        results.append([algo_name, batch_size, workers, fps])

    # --- 4. æŠ¥å‘Šç»“æœ ---
    print("\n\n" + "=" * 70)
    print("      æœç´¢ç»“æœæŠ¥å‘Š")
    print("=" * 70)

    # ä½¿ç”¨ polars åˆ›å»ºå’Œæ ¼å¼åŒ–è¡¨æ ¼
    df = pl.DataFrame(
        results, schema=["Algorithm", "Batch Size", "Workers", "Sync FPS"], orient="row"
    )
    df = df.sort("Sync FPS", descending=True)

    # å°† FPS æ ¼å¼åŒ–ä¸ºå¸¦é€—å·çš„æ•´æ•°
    df = df.with_columns(
        pl.col("Sync FPS").map_elements(lambda x: "{:,.0f}".format(x)).alias("Sync FPS")
    )

    print(str(df))

    print("\n" + "-" * 70)
    best_config = df.row(0)
    print("\nğŸ† æœ€ä¼˜é…ç½®å»ºè®® ğŸ†")
    print(f"\n  - ç®—æ³•:         {best_config[0]}")
    print(f"  - æ‰¹å¤„ç†å¤§å°:   {best_config[1]}")
    print(f"  - å·¥ä½œè¿›ç¨‹æ•°:   {best_config[2]}")
    print(f"  - é¢„ä¼°åŒæ­¥FPS:  {best_config[3]}")


if __name__ == "__main__":
    mp.set_start_method("spawn", force=True)
    main()
